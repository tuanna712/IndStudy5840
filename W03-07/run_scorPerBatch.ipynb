{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch CNN - CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the full dataset for training and testing.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DOWNLOAD = False\n",
    "SUBSET = 0\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomAffine(degrees=(-5, 5), translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data', \n",
    "                                            train=True,\n",
    "                                            download=DOWNLOAD,\n",
    "                                            transform=train_transform,\n",
    "                                            )\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data', \n",
    "                                            train=False,\n",
    "                                            download=DOWNLOAD,\n",
    "                                            transform=test_transform,\n",
    "                                            )\n",
    "if SUBSET != 0:\n",
    "    subset_indices = list(range(SUBSET))\n",
    "    train_set = torch.utils.data.Subset(train_dataset, subset_indices)\n",
    "    test_set = torch.utils.data.Subset(test_dataset, subset_indices)\n",
    "    print(f\"Using a subset of {SUBSET} samples for training and testing.\")\n",
    "else:\n",
    "    train_set, test_set = train_dataset, test_dataset\n",
    "    print(\"Using the full dataset for training and testing.\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Class names\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_performance(save_path,\n",
    "                     train_losses, test_losses, train_errs, \n",
    "                     test_errs, train_accs, test_acc, run_times,\n",
    "                     n_step):\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    performance = {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_errs': train_errs,\n",
    "        'test_errs': test_errs,\n",
    "        'train_accs': train_accs,\n",
    "        'test_acc': test_acc,\n",
    "        'run_time': run_times,\n",
    "        'n_step': n_step,\n",
    "    }\n",
    "    with open(f'{save_path}/SGD_{n_step}.json', 'w') as f:\n",
    "        json.dump(performance, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, test_loader=test_loader):\n",
    "    model.eval() \n",
    "    _test_acc, _test_err, _test_loss, total_test = 0, 0, 0, 0\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            _test_acc += (predicted == labels).sum().item()\n",
    "            _test_err += (predicted != labels).sum().item()\n",
    "            _test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    test_loss = _test_loss / total_test\n",
    "    test_err = 100 * _test_err / total_test\n",
    "    test_acc = 100 * _test_acc / total_test\n",
    "\n",
    "    return test_loss, test_err, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleCNN\n",
    "from optim.sgd_sngl import OneStepSGD\n",
    "from optim.sgd_mult import ManyStepSGD\n",
    "import time \n",
    "\n",
    "def modeling(n_step=2, n_epochs=15, lr=0.133, momentum=0, threshold=90):\n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if n_step == 1:\n",
    "        optimizer = OneStepSGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    else:\n",
    "        optimizer = ManyStepSGD(model.parameters(), lr=lr, momentum=momentum, n_step=n_step)\n",
    "\n",
    "    train_losses, test_losses, train_errs, test_errs, train_accs, test_accs, run_times = [], [], [], [], [], [], []\n",
    "\n",
    "    for i, epoch in enumerate(range(n_epochs)):\n",
    "        print(f\"Epoch: {i+1}/{n_epochs}\")\n",
    "        model.train()\n",
    "        _start = time.time()\n",
    "        run_time = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = loss.item()\n",
    "            # Training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _train_err = (predicted != labels).sum().item()\n",
    "            _train_acc = (predicted == labels).sum().item()\n",
    "            \n",
    "            _batch_train_loss = running_loss / labels.size(0)\n",
    "            _batch_train_acc = 100 * _train_acc / labels.size(0)\n",
    "            _batch_train_err = 100 * _train_err / labels.size(0)\n",
    "            \n",
    "            test_loss, test_err, test_acc = evaluate_model(model, criterion, test_loader)\n",
    "\n",
    "            train_losses.append(_batch_train_loss)\n",
    "            train_errs.append(_batch_train_err)\n",
    "            train_accs.append(_batch_train_acc)\n",
    "            test_losses.append(test_loss)\n",
    "            test_errs.append(test_err)\n",
    "            test_accs.append(test_acc)\n",
    "            \n",
    "        run_time = time.time() - _start\n",
    "        run_times.append(run_time)\n",
    "        if epoch % 1 == 0:\n",
    "            print(f'E [{epoch+1}/{n_epochs}]. train_loss_acc: {train_losses[-1]:.4f}, {train_errs[-1]}%, '\n",
    "                    f'test_acc: {test_accs[-1]:.2f}%')\n",
    "        if _batch_train_acc >= threshold:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with train acc {_batch_train_acc:.2f}%\")\n",
    "            break\n",
    "        \n",
    "    return train_losses, test_losses, train_errs, test_errs, train_accs, test_accs, run_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "E [1/50]. train_loss_acc: 0.0196, 61.25%, test_acc: 42.78%\n",
      "Epoch: 2/50\n",
      "E [2/50]. train_loss_acc: 0.0209, 61.25%, test_acc: 47.20%\n",
      "Epoch: 3/50\n",
      "E [3/50]. train_loss_acc: 0.0167, 52.5%, test_acc: 59.83%\n",
      "Epoch: 4/50\n",
      "E [4/50]. train_loss_acc: 0.0101, 26.25%, test_acc: 66.08%\n",
      "Epoch: 5/50\n",
      "E [5/50]. train_loss_acc: 0.0110, 25.0%, test_acc: 68.02%\n",
      "Epoch: 6/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.133\u001b[39m\n\u001b[1;32m      5\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_losses, test_losses, train_errs, test_errs, train_accs, test_accs, run_times \u001b[38;5;241m=\u001b[39m \u001b[43mmodeling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores/batch_scores\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m save_performance(save_path,\n\u001b[1;32m     13\u001b[0m                  train_losses, test_losses, train_errs, \n\u001b[1;32m     14\u001b[0m                  test_errs, train_accs, test_accs, run_times, n_step\u001b[38;5;241m=\u001b[39mn_step,\n\u001b[1;32m     15\u001b[0m                  )\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mmodeling\u001b[0;34m(n_step, n_epochs, lr, momentum, threshold)\u001b[0m\n\u001b[1;32m     42\u001b[0m _batch_train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m _train_acc \u001b[38;5;241m/\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m _batch_train_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m _train_err \u001b[38;5;241m/\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m test_loss, test_err, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(_batch_train_loss)\n\u001b[1;32m     48\u001b[0m train_errs\u001b[38;5;241m.\u001b[39mappend(_batch_train_err)\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, criterion, test_loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m _test_acc, _test_err, _test_loss, total_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torchvision/datasets/cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/curc/sw/conda_env/pytorch-cuda-12.4/lib/python3.12/site-packages/torch/nn/modules/module.py:1555\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1556\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from plot import metrics_plot\n",
    "n_epochs = 50\n",
    "n_step = 1\n",
    "lr = 0.133\n",
    "threshold = 90\n",
    "train_losses, test_losses, train_errs, test_errs, train_accs, test_accs, run_times = modeling(n_step=n_step, \n",
    "                                                                                   n_epochs=n_epochs, \n",
    "                                                                                   lr=lr,\n",
    "                                                                                   threshold=threshold,\n",
    "                                                                                  )\n",
    "save_path = 'scores/batch_scores'\n",
    "save_performance(save_path,\n",
    "                 train_losses, test_losses, train_errs, \n",
    "                 test_errs, train_accs, test_accs, run_times, n_step=n_step,\n",
    "                 )\n",
    "metrics_plot(n_epochs, train_losses, test_losses, train_accs, test_accs, train_errs, test_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import metrics_plot\n",
    "n_epochs = 50\n",
    "n_step = 10\n",
    "lr = 0.133\n",
    "threshold = 90\n",
    "train_losses, test_losses, train_errs, test_errs, train_accs, test_accs, run_times = modeling(n_step=n_step, \n",
    "                                                                                   n_epochs=n_epochs, \n",
    "                                                                                   lr=lr,\n",
    "                                                                                   threshold=threshold,\n",
    "                                                                                  )\n",
    "save_path = 'scores/batch_scores'\n",
    "save_performance(save_path,\n",
    "                 train_losses, test_losses, train_errs, \n",
    "                 test_errs, train_accs, test_accs, run_times, n_step=n_step,\n",
    "                 )\n",
    "metrics_plot(n_epochs, train_losses, test_losses, train_accs, test_accs, train_errs, test_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch24",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
